{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepComp_Comparison_LSTM_Solar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1cvkVbqmof-zArH3L2Z7t-GiyM7mS6iHx",
      "authorship_tag": "ABX9TyMFmQvGjf+Cm/jtBxL1idnh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7FaeNtgi2yT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T8H6Pp_6evf"
      },
      "source": [
        "Renewable_Energy = \"Solar_PBE\"\r\n",
        "\r\n",
        "try:\r\n",
        "    address = \"/content/drive/My Drive/Doctor/Research/DRL/Colab/\"\r\n",
        "    data_train_csv1 = pd.read_csv(address+Renewable_Energy+'_16.csv', index_col=0)\r\n",
        "\r\n",
        "except:\r\n",
        "    address = \"\"\r\n",
        "    data_train_csv1 = pd.read_csv(address+Renewable_Energy+'_16.csv', index_col=0)\r\n",
        "\r\n",
        "data_train_csv2 = pd.read_csv(address+Renewable_Energy+'_17.csv', index_col=0)\r\n",
        "data_train_csv  = pd.concat([data_train_csv1, data_train_csv2])\r\n",
        "data_val_csv    = pd.read_csv(address+Renewable_Energy+'_18.csv', index_col=0)\r\n",
        "data_test_csv   = pd.read_csv(address+Renewable_Energy+'_19.csv', index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uMkIVSIXceM"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "unit = 4 #unit: 15 minute\n",
        "\n",
        "RE_Capacity1 = max(data_train_csv['Power(MW)'])\n",
        "RE_Capacity2 = max(data_val_csv['Power(MW)'])\n",
        "RE_Capacity3 = max(data_test_csv['Power(MW)'])\n",
        "\n",
        "size_train0 = int(len(data_train_csv)/unit)\n",
        "size_val0   = int(len(data_val_csv)/unit)\n",
        "size_test0  = int(len(data_test_csv)/unit)\n",
        "\n",
        "data_train0 = []\n",
        "data_train  = []\n",
        "for i in range(size_train0):\n",
        "    data_train0 += [round(pd.Series.mean(data_train_csv['Power(MW)'][i*unit:(i+1)*unit])/RE_Capacity1, 3)]\n",
        "    data_train  += [data_train0[i]] if data_train0[i] > 0 else []\n",
        "\n",
        "data_val0 = []\n",
        "data_val  = []\n",
        "for i in range(size_val0):\n",
        "    data_val0 += [round(pd.Series.mean(data_val_csv['Power(MW)'][i*unit:(i+1)*unit])/RE_Capacity2, 3)]\n",
        "    data_val  += [data_val0[i]] if data_val0[i] > 0 else []\n",
        "\n",
        "data_test0 = []\n",
        "data_test  = []\n",
        "for i in range(size_test0):\n",
        "    data_test0 += [round(pd.Series.mean(data_test_csv['Power(MW)'][i*unit:(i+1)*unit])/RE_Capacity3, 3)]\n",
        "    data_test  += [data_test0[i]] if data_test0[i] > 0 else []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG4iSzn3i4nj"
      },
      "source": [
        "# LSTM\n",
        "\n",
        "n_layers       = 1\n",
        "in_size        = 1\n",
        "hidden_size    = 16\n",
        "out_size       = 1\n",
        "batch_size     = 128\n",
        "learning_rate  = 0.001\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.fc_in  = nn.Linear(in_size, hidden_size)\n",
        "        self.rnn    = nn.LSTM(hidden_size, hidden_size, n_layers, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hidden_size, out_size)\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        x = F.relu(self.fc_in(x))\n",
        "        x = x.view(1, -1, hidden_size)\n",
        "        x, hidden = self.rnn(x, hidden)\n",
        "        out = self.fc_out(x)\n",
        "        out = F.relu(out.view(-1, out_size))\n",
        "        return out, hidden\n",
        "        \n",
        "def train_net(model, batch, optimizer):\n",
        "    x, h, y = batch[0], batch[1], batch[2]\n",
        "    loss = F.mse_loss(model.forward(x, h)[0], y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nd2JyvdkNEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa8aefa-27ab-4792-d50b-e425a1fa57f8"
      },
      "source": [
        "# Training LSTM\n",
        "\n",
        "total_epoch    = 100\n",
        "print_interval = 10\n",
        "\n",
        "model = LSTM()\n",
        "size_train = len(data_train)\n",
        "size_val = len(data_val)\n",
        "size_test = len(data_test)\n",
        "\n",
        "train_input = np.zeros((size_train-1, 1))\n",
        "train_output = np.zeros((size_train-1, 1))\n",
        "for i in range(size_train-1):\n",
        "    train_input[i,:] = data_train[i]\n",
        "    train_output[i,:] = data_train[i+1]\n",
        "\n",
        "val_input = np.zeros((size_val-1, 1))\n",
        "val_output = np.zeros((size_val-1, 1))\n",
        "for i in range(size_val-1):\n",
        "    val_input[i,:] = data_val[i]\n",
        "    val_output[i,:] = data_val[i+1]\n",
        "\n",
        "test_input = np.zeros((size_test-1, 1))\n",
        "test_output = np.zeros((size_test-1, 1))\n",
        "for i in range(size_test-1):\n",
        "    test_input[i,:] = data_test[i]\n",
        "    test_output[i,:] = data_test[i+1]\n",
        "\n",
        "total_batch = int((size_train-1)/batch_size) + 1\n",
        "pred_train, pred_val, pred_test = [], [], [] # Predicted Value\n",
        "mape_train, mape_val, mape_test = [], [], [] # Mean Absolute Percentage Error\n",
        "\n",
        "hidden = (torch.zeros([n_layers, 1, hidden_size], dtype=torch.float), torch.zeros([n_layers, 1, hidden_size], dtype=torch.float))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "for epoch in range(total_epoch):\n",
        "    for i in range(total_batch):\n",
        "        batch_x = torch.tensor(train_input[batch_size*i:batch_size*(i+1),:] ,dtype=torch.float)\n",
        "        batch_y = torch.tensor(train_output[batch_size*i:batch_size*(i+1),:] ,dtype=torch.float)\n",
        "        batch = [batch_x, hidden, batch_y]\n",
        "        train_net(model, batch, optimizer)\n",
        "        _, hidden = model.forward(batch_x, hidden)\n",
        "        hidden = (hidden[0].detach(), hidden[1].detach())\n",
        "\n",
        "    hidden = (torch.zeros([n_layers, 1, hidden_size], dtype=torch.float), torch.zeros([n_layers, 1, hidden_size], dtype=torch.float))\n",
        "    if epoch == 0 or (epoch+1) % print_interval == 0:\n",
        "        train_predict = model.forward(torch.tensor(train_input, dtype=torch.float), hidden)[0].detach().numpy()\n",
        "        pred_train += [list(train_predict.flatten())]\n",
        "        mape_train += [list(np.abs(train_predict - train_output).flatten()/train_output.flatten())]\n",
        "        \n",
        "        val_predict = model.forward(torch.tensor(val_input, dtype=torch.float), hidden)[0].detach().numpy()\n",
        "        pred_val += [list(val_predict.flatten())]\n",
        "        mape_val += [list(np.abs(val_predict - val_output).flatten()/val_output.flatten())]\n",
        "        \n",
        "        test_predict = model.forward(torch.tensor(test_input, dtype=torch.float), hidden)[0].detach().numpy()\n",
        "        pred_test += [list(test_predict.flatten())]\n",
        "        mape_test += [list(np.abs(test_predict - test_output).flatten()/test_output.flatten())]\n",
        "\n",
        "        MAPE_train = round(100*np.mean(mape_train[-1]),2)\n",
        "        MAPE_val   = round(100*np.mean(mape_val[-1]),2)\n",
        "        MAPE_test  = round(100*np.mean(mape_test[-1]),2)\n",
        "\n",
        "        print(\"epoch: {}\".format(epoch+1))\n",
        "        print(\"MAPE_train: {}%\".format(MAPE_train).ljust(25), end=\"\")\n",
        "        print(\"MAPE_val: {}%\".format(MAPE_val).ljust(25), end=\"\")\n",
        "        print(\"MAPE_test: {}%\".format(MAPE_test).ljust(25))\n",
        "        print(\"------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1\n",
            "MAPE_train: 1194.55%     MAPE_val: 1197.87%       MAPE_test: 1170.64%      \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 10\n",
            "MAPE_train: 95.96%       MAPE_val: 82.77%         MAPE_test: 89.19%        \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 20\n",
            "MAPE_train: 63.18%       MAPE_val: 56.31%         MAPE_test: 58.71%        \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 30\n",
            "MAPE_train: 51.79%       MAPE_val: 47.74%         MAPE_test: 48.8%         \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 40\n",
            "MAPE_train: 44.19%       MAPE_val: 41.6%          MAPE_test: 42.33%        \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 50\n",
            "MAPE_train: 40.88%       MAPE_val: 39.53%         MAPE_test: 39.31%        \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 60\n",
            "MAPE_train: 39.72%       MAPE_val: 38.69%         MAPE_test: 37.82%        \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 70\n",
            "MAPE_train: 38.91%       MAPE_val: 38.32%         MAPE_test: 37.09%        \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 80\n",
            "MAPE_train: 38.46%       MAPE_val: 38.33%         MAPE_test: 36.91%        \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 90\n",
            "MAPE_train: 38.26%       MAPE_val: 38.27%         MAPE_test: 36.96%        \n",
            "------------------------------------------------------------------------------------------\n",
            "epoch: 100\n",
            "MAPE_train: 38.32%       MAPE_val: 38.43%         MAPE_test: 37.26%        \n",
            "------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVxRZ0gHZbmn"
      },
      "source": [
        "# Produce results\n",
        "\n",
        "# select_num = np.argmin(np.mean(mape_val,axis=1))\n",
        "# select_train = pd.DataFrame(np.array(pred_train[select_num][:]))\n",
        "# select_val = pd.DataFrame(np.array(pred_val[select_num][:]))\n",
        "# select_test = pd.DataFrame(np.array(pred_test[select_num][:]))\n",
        "# select_train.to_csv(address+Renewable_Energy+\"_Model1_train.csv\")\n",
        "# select_val.to_csv(address+Renewable_Energy+\"_Model1_val.csv\")\n",
        "# select_test.to_csv(address+Renewable_Energy+\"_Model1_NEC.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}