{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepComp_Comparison_SARSA_Solar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MNeyVXVucm8Rke-hDQ1tSP_8wOfyU8_7",
      "authorship_tag": "ABX9TyN1B80qncnXalRhvRxR+3mQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfXXnaufrfAQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhhm33nh8Agv"
      },
      "source": [
        "Renewable_Energy = \"Solar_PBE\"\r\n",
        "\r\n",
        "try:\r\n",
        "    address = \"/content/drive/My Drive/Doctor/Research/DRL/Colab/\"\r\n",
        "    data_train_csv1 = pd.read_csv(address+Renewable_Energy+'_16.csv', index_col=0)\r\n",
        "\r\n",
        "except:\r\n",
        "    address = \"\"\r\n",
        "    data_train_csv1 = pd.read_csv(address+Renewable_Energy+'_16.csv', index_col=0)\r\n",
        "\r\n",
        "data_train_csv2 = pd.read_csv(address+Renewable_Energy+'_17.csv', index_col=0)\r\n",
        "data_train_csv  = pd.concat([data_train_csv1, data_train_csv2])\r\n",
        "data_val_csv    = pd.read_csv(address+Renewable_Energy+'_18.csv', index_col=0)\r\n",
        "data_test_csv   = pd.read_csv(address+Renewable_Energy+'_19.csv', index_col=0)\r\n",
        "\r\n",
        "train_predict = np.array(pd.read_csv(address+\"results/\"+Renewable_Energy+\"_Model1_train.csv\", index_col=0))\r\n",
        "val_predict = np.array(pd.read_csv(address+\"results/\"+Renewable_Energy+\"_Model1_val.csv\", index_col=0))\r\n",
        "test_predict = np.array(pd.read_csv(address+\"results/\"+Renewable_Energy+\"_Model1_NEC.csv\", index_col=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEaT0jerrgg-"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Battery_Size = 0.5\n",
        "unit         = 4 #unit: 15 minute\n",
        "\n",
        "RE_Capacity1 = max(data_train_csv['Power(MW)'])\n",
        "RE_Capacity2 = max(data_val_csv['Power(MW)'])\n",
        "RE_Capacity3 = max(data_test_csv['Power(MW)'])\n",
        "\n",
        "size_train0 = int(len(data_train_csv)/unit)\n",
        "size_val0   = int(len(data_val_csv)/unit)\n",
        "size_test0  = int(len(data_test_csv)/unit)\n",
        "\n",
        "data_train0 = []\n",
        "data_train  = []\n",
        "for i in range(size_train0):\n",
        "    data_train0 += [round(pd.Series.mean(data_train_csv['Power(MW)'][i*unit:(i+1)*unit])/RE_Capacity1, 3)]\n",
        "    data_train  += [data_train0[i]] if data_train0[i] > 0 else []\n",
        "\n",
        "data_val0 = []\n",
        "data_val  = []\n",
        "for i in range(size_val0):\n",
        "    data_val0 += [round(pd.Series.mean(data_val_csv['Power(MW)'][i*unit:(i+1)*unit])/RE_Capacity2, 3)]\n",
        "    data_val  += [data_val0[i]] if data_val0[i] > 0 else []\n",
        "\n",
        "data_test0 = []\n",
        "data_test  = []\n",
        "for i in range(size_test0):\n",
        "    data_test0 += [round(pd.Series.mean(data_test_csv['Power(MW)'][i*unit:(i+1)*unit])/RE_Capacity3, 3)]\n",
        "    data_test  += [data_test0[i]] if data_test0[i] > 0 else []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jC6yhkysL2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6c1dc5-ebac-4a9e-c5b4-6d8c5f91909c"
      },
      "source": [
        "size_train = len(data_train)\n",
        "size_val = len(data_val)\n",
        "size_test = len(data_test)\n",
        "\n",
        "train_input = np.zeros((size_train-1, 1))\n",
        "train_output = np.zeros((size_train-1, 1))\n",
        "for i in range(size_train-1):\n",
        "    train_input[i,:] = data_train[i]\n",
        "    train_output[i,:] = data_train[i+1]\n",
        "\n",
        "val_input = np.zeros((size_val-1, 1))\n",
        "val_output = np.zeros((size_val-1, 1))\n",
        "for i in range(size_val-1):\n",
        "    val_input[i,:] = data_val[i]\n",
        "    val_output[i,:] = data_val[i+1]\n",
        "\n",
        "test_input = np.zeros((size_test-1, 1))\n",
        "test_output = np.zeros((size_test-1, 1))\n",
        "for i in range(size_test-1):\n",
        "    test_input[i,:] = data_test[i]\n",
        "    test_output[i,:] = data_test[i+1]\n",
        "\n",
        "print(\"MAPE_train: {}%\".format(round(100*np.mean(np.abs(train_predict - train_output)/train_output),2)).ljust(25), end=\"\")\n",
        "print(\"MAPE_val: {}%\".format(round(100*np.mean(np.abs(val_predict - val_output)/val_output),2)).ljust(25), end=\"\")\n",
        "print(\"MAPE_test: {}%\".format(round(100*np.mean(np.abs(test_predict - test_output)/test_output),2)).ljust(25))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAPE_train: 36.56%       MAPE_val: 36.96%         MAPE_test: 36.16%        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLit2DnnrhlV"
      },
      "source": [
        "# SARSA\n",
        "\n",
        "in_size       = 1\n",
        "out_size      = 5\n",
        "gamma         = 0.99\n",
        "epsilon       = 0.9\n",
        "batch_size    = 128\n",
        "learning_rate = 0.001\n",
        "\n",
        "class SARSA(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SARSA, self).__init__()\n",
        "        self.fc = nn.Linear(in_size, out_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "        \n",
        "def train_net(model, batch, optimizer):\n",
        "    s_lst, a_lst, r_lst, s_prime_lst = [], [], [], []\n",
        "\n",
        "    for transition in batch:\n",
        "        s, a, r, s_prime = transition\n",
        "        s_lst.append(s)\n",
        "        a_lst.append([a])\n",
        "        r_lst.append([r])\n",
        "        s_prime_lst.append(s_prime)\n",
        "\n",
        "    s,a,r,s_prime = torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
        "                    torch.tensor(r_lst, dtype=torch.float), torch.tensor(s_prime_lst, dtype=torch.float)\n",
        "            \n",
        "    for i in range(10):\n",
        "        q_out = model.forward(s).gather(1,a)\n",
        "        target = r + gamma * torch.mean(model.forward(s_prime))\n",
        "        loss = F.mse_loss(q_out, target)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VOEy-4Ortn2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3858a4c1-5f71-42f2-aff7-4ba8e56bf9c5"
      },
      "source": [
        "# Training SARSA\n",
        "\n",
        "E_max   = Battery_Size\n",
        "tdelta  = unit/4\n",
        "eff_c   = 0.9\n",
        "eff_d   = 0.9\n",
        "soc_min = 0.1\n",
        "soc_max = 0.9\n",
        "P_cmax  = Battery_Size/3\n",
        "P_dmax  = Battery_Size/3\n",
        "beta_c  = 0.01\n",
        "beta_d  = 0.01\n",
        "\n",
        "E_cmax = eff_c*P_cmax*tdelta\n",
        "E_dmax = (1/eff_d)*P_dmax*tdelta\n",
        "C_max  = int(out_size/2)\n",
        "\n",
        "total_episode = 20\n",
        "print_interval = 1\n",
        "\n",
        "model = SARSA()\n",
        "act_train,  act_val,  act_test  = [], [], [] # Controlled Value\n",
        "mape_train, mape_val, mape_test = [], [], [] # Mean Absolute Percentage Error\n",
        "ccr_train,  ccr_val,  ccr_test  = [], [], [] # Complete Compensation Ratio\n",
        "\n",
        "batch = collections.deque(maxlen=batch_size+1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "for n_epi in range(total_episode):\n",
        "    act_train  += [[]]; act_val  += [[]]; act_test  += [[]]\n",
        "    mape_train += [[]]; mape_val += [[]]; mape_test += [[]]\n",
        "    ccr_train  += [[]]; ccr_val  += [[]]; ccr_test  += [[]]\n",
        "\n",
        "    state = [E_max/2]\n",
        "    i = 0\n",
        "    while i < size_train-1:\n",
        "        for t in range(batch_size):\n",
        "            coin = torch.rand(1).item()\n",
        "            if coin < epsilon:\n",
        "                action = np.random.choice(range(out_size))\n",
        "            else:\n",
        "                Qout = model.forward(torch.tensor(state, dtype=torch.float))\n",
        "                action = np.argmax(Qout.tolist())\n",
        "            E_c = min(max((E_cmax/C_max)*(action-C_max), 0.0), E_max*soc_max - state[0])\n",
        "            E_d = min(max((E_dmax/C_max)*(C_max-action), 0.0), state[0] - E_max*soc_min)\n",
        "\n",
        "            real = train_output[i][0] + eff_d*E_d/tdelta - (1/eff_c)*E_c/tdelta\n",
        "            pred = train_predict[i][0]\n",
        "\n",
        "            E = state[0] + E_c - E_d\n",
        "            P_climit = min(P_cmax, (1/eff_c)*(E_max*soc_max - E)/tdelta)\n",
        "            P_dlimit = min(P_dmax, eff_d*(E - E_max*soc_min)/tdelta)\n",
        "            P_c = min(max(real-pred, 0), P_climit)\n",
        "            P_d = min(max(pred-real, 0), P_dlimit)\n",
        "            E_prime = E + eff_c*P_c*tdelta - (1/eff_d)*P_d*tdelta\n",
        "            disp = 0.0 if np.isclose(real - P_c + P_d, 0) else real - P_c + P_d\n",
        "            error = pred - disp\n",
        "            error_function = abs(error) + beta_c*P_c + beta_d*P_d\n",
        "\n",
        "            next_state = [E_prime]\n",
        "            reward = -error_function\n",
        "            batch.append((state, action, reward, next_state))\n",
        "            state = next_state[:]\n",
        "\n",
        "            act_train[n_epi]  += [E_c - E_d]\n",
        "            mape_train[n_epi]  += [abs((pred-disp)/disp)] if disp != 0 else [0]\n",
        "            ccr_train[n_epi] += [1 if np.isclose(pred-disp,0) else 0]\n",
        "            i += 1\n",
        "            if i == size_train-1:\n",
        "                break\n",
        "\n",
        "        if n_epi != 0:\n",
        "            train_net(model, batch, optimizer)\n",
        "    \n",
        "    state = [E_max/2]\n",
        "    for k in range(size_val-1):\n",
        "        Qout = model.forward(torch.tensor(state, dtype=torch.float))\n",
        "        action = np.argmax(Qout.tolist())\n",
        "        E_c = min(max((E_cmax/C_max)*(action-C_max), 0.0), E_max*soc_max - state[0])\n",
        "        E_d = min(max((E_dmax/C_max)*(C_max-action), 0.0), state[0] - E_max*soc_min)\n",
        "\n",
        "        real = val_output[k][0] + eff_d*E_d/tdelta - (1/eff_c)*E_c/tdelta\n",
        "        pred = val_predict[k][0]\n",
        "\n",
        "        E = state[0] + E_c - E_d\n",
        "        P_climit = min(P_cmax, (1/eff_c)*(E_max*soc_max - E)/tdelta)\n",
        "        P_dlimit = min(P_dmax, eff_d*(E - E_max*soc_min)/tdelta)\n",
        "        P_c = min(max(real-pred, 0), P_climit)\n",
        "        P_d = min(max(pred-real, 0), P_dlimit)\n",
        "        E_prime = E + eff_c*P_c*tdelta - (1/eff_d)*P_d*tdelta\n",
        "        disp = 0.0 if np.isclose(real - P_c + P_d, 0) else real - P_c + P_d\n",
        "        error = pred - disp\n",
        "        error_function = abs(error) + beta_c*P_c + beta_d*P_d\n",
        "\n",
        "        next_state = [E_prime]\n",
        "        state = next_state[:]\n",
        "\n",
        "        act_val[n_epi]  += [E_c - E_d]\n",
        "        mape_val[n_epi]  += [abs((pred-disp)/disp)] if disp != 0 else [0]\n",
        "        ccr_val[n_epi] += [1 if np.isclose(pred-disp,0) else 0]\n",
        "    \n",
        "    state = [E_max/2]\n",
        "    for l in range(size_test-1):\n",
        "        Qout = model.forward(torch.tensor(state, dtype=torch.float))\n",
        "        action = np.argmax(Qout.tolist())\n",
        "        E_c = min(max((E_cmax/C_max)*(action-C_max), 0.0), E_max*soc_max - state[0])\n",
        "        E_d = min(max((E_dmax/C_max)*(C_max-action), 0.0), state[0] - E_max*soc_min)\n",
        "\n",
        "        real = test_output[l][0] + eff_d*E_d/tdelta - (1/eff_c)*E_c/tdelta\n",
        "        pred = test_predict[l][0]\n",
        "\n",
        "        E = state[0] + E_c - E_d\n",
        "        P_climit = min(P_cmax, (1/eff_c)*(E_max*soc_max - E)/tdelta)\n",
        "        P_dlimit = min(P_dmax, eff_d*(E - E_max*soc_min)/tdelta)\n",
        "        P_c = min(max(real-pred, 0), P_climit)\n",
        "        P_d = min(max(pred-real, 0), P_dlimit)\n",
        "        E_prime = E + eff_c*P_c*tdelta - (1/eff_d)*P_d*tdelta\n",
        "        disp = 0.0 if np.isclose(real - P_c + P_d, 0) else real - P_c + P_d\n",
        "        error = pred - disp\n",
        "        error_function = abs(error) + beta_c*P_c + beta_d*P_d\n",
        "\n",
        "        next_state = [E_prime]\n",
        "        state = next_state[:]\n",
        "\n",
        "        act_test[n_epi]  += [E_c - E_d]\n",
        "        mape_test[n_epi]  += [abs((pred-disp)/disp)] if disp != 0 else [0]\n",
        "        ccr_test[n_epi] += [1 if np.isclose(pred-disp,0) else 0]\n",
        "    \n",
        "    if (n_epi+1)%print_interval == 0:\n",
        "        MAPE_train  = round(100*np.mean(mape_train[n_epi]),2)\n",
        "        MAPE_val    = round(100*np.mean(mape_val[n_epi]),2)\n",
        "        MAPE_test   = round(100*np.mean(mape_test[n_epi]),2)\n",
        "        CCR_train = round(np.mean(ccr_train[n_epi]),3)\n",
        "        CCR_val   = round(np.mean(ccr_val[n_epi]),3)\n",
        "        CCR_test  = round(np.mean(ccr_test[n_epi]),3)\n",
        "\n",
        "        print(\"episode: {}\".format(n_epi+1))\n",
        "        print(\"MAPE_train: {}%\".format(MAPE_train).ljust(25), end=\"\")\n",
        "        print(\"MAPE_val: {}%\".format(MAPE_val).ljust(25), end=\"\")\n",
        "        print(\"MAPE_test: {}%\".format(MAPE_test).ljust(25))\n",
        "        print(\"CCR_train: {}\".format(CCR_train).ljust(25), end=\"\")\n",
        "        print(\"CCR_val: {}\".format(CCR_val).ljust(25), end=\"\")\n",
        "        print(\"CCR_test: {}\".format(CCR_test).ljust(25))\n",
        "        print(\"------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode: 1\n",
            "MAPE_train: 23.57%       MAPE_val: 67.27%         MAPE_test: 89.77%        \n",
            "CCR_train: 0.685         CCR_val: 0.482           CCR_test: 0.456          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 2\n",
            "MAPE_train: 30.5%        MAPE_val: 57.25%         MAPE_test: 68.27%        \n",
            "CCR_train: 0.695         CCR_val: 0.609           CCR_test: 0.622          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 3\n",
            "MAPE_train: 29.04%       MAPE_val: 2.77%          MAPE_test: 2.58%         \n",
            "CCR_train: 0.705         CCR_val: 0.81            CCR_test: 0.825          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 4\n",
            "MAPE_train: 23.14%       MAPE_val: 3.49%          MAPE_test: 3.3%          \n",
            "CCR_train: 0.715         CCR_val: 0.812           CCR_test: 0.826          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 5\n",
            "MAPE_train: 20.15%       MAPE_val: 3.25%          MAPE_test: 2.96%         \n",
            "CCR_train: 0.712         CCR_val: 0.809           CCR_test: 0.827          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 6\n",
            "MAPE_train: 22.44%       MAPE_val: 3.25%          MAPE_test: 2.96%         \n",
            "CCR_train: 0.71          CCR_val: 0.809           CCR_test: 0.827          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 7\n",
            "MAPE_train: 27.43%       MAPE_val: 3.25%          MAPE_test: 2.96%         \n",
            "CCR_train: 0.72          CCR_val: 0.809           CCR_test: 0.827          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 8\n",
            "MAPE_train: 21.35%       MAPE_val: 4.92%          MAPE_test: 5.71%         \n",
            "CCR_train: 0.724         CCR_val: 0.672           CCR_test: 0.665          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 9\n",
            "MAPE_train: 18.09%       MAPE_val: 2.88%          MAPE_test: 2.68%         \n",
            "CCR_train: 0.723         CCR_val: 0.817           CCR_test: 0.835          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 10\n",
            "MAPE_train: 16.94%       MAPE_val: 3.25%          MAPE_test: 2.96%         \n",
            "CCR_train: 0.728         CCR_val: 0.809           CCR_test: 0.827          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 11\n",
            "MAPE_train: 21.65%       MAPE_val: 3.25%          MAPE_test: 2.96%         \n",
            "CCR_train: 0.719         CCR_val: 0.809           CCR_test: 0.827          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 12\n",
            "MAPE_train: 23.2%        MAPE_val: 4.92%          MAPE_test: 5.71%         \n",
            "CCR_train: 0.719         CCR_val: 0.672           CCR_test: 0.665          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 13\n",
            "MAPE_train: 19.3%        MAPE_val: 3.25%          MAPE_test: 2.96%         \n",
            "CCR_train: 0.719         CCR_val: 0.809           CCR_test: 0.827          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 14\n",
            "MAPE_train: 20.2%        MAPE_val: 3.25%          MAPE_test: 2.96%         \n",
            "CCR_train: 0.722         CCR_val: 0.809           CCR_test: 0.827          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 15\n",
            "MAPE_train: 21.97%       MAPE_val: 5.31%          MAPE_test: 6.11%         \n",
            "CCR_train: 0.721         CCR_val: 0.662           CCR_test: 0.653          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 16\n",
            "MAPE_train: 29.85%       MAPE_val: 3.25%          MAPE_test: 2.96%         \n",
            "CCR_train: 0.727         CCR_val: 0.809           CCR_test: 0.827          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 17\n",
            "MAPE_train: 21.45%       MAPE_val: 2.15%          MAPE_test: 1.71%         \n",
            "CCR_train: 0.722         CCR_val: 0.842           CCR_test: 0.864          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 18\n",
            "MAPE_train: 20.19%       MAPE_val: 3.25%          MAPE_test: 2.96%         \n",
            "CCR_train: 0.719         CCR_val: 0.809           CCR_test: 0.827          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 19\n",
            "MAPE_train: 19.01%       MAPE_val: 5.3%           MAPE_test: 5.39%         \n",
            "CCR_train: 0.722         CCR_val: 0.71            CCR_test: 0.701          \n",
            "------------------------------------------------------------------------------------------\n",
            "episode: 20\n",
            "MAPE_train: 22.38%       MAPE_val: 3.91%          MAPE_test: 3.61%         \n",
            "CCR_train: 0.72          CCR_val: 0.754           CCR_test: 0.783          \n",
            "------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0o8d2xWyrzv"
      },
      "source": [
        "# Produce results\r\n",
        "#\r\n",
        "#select_num = np.argmin(np.mean(mape_val,axis=1))\r\n",
        "#select = pd.DataFrame(np.array(act_test[select_num][:]))\r\n",
        "#select.to_csv(address+Renewable_Energy+\"_Model2_ECC+_\"+str(int(100*E_max))+\".csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}