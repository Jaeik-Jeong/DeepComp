{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOONHaUBnEepEpi2/VCbcA3"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"sbHJdT8wYOpD"},"source":["import pandas as pd\n","import numpy as np\n","import collections\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g4ulsTOX8Fr3"},"source":["Renewable_Energy = \"Wind_Wallonie_Elia\"\n","address = \"https://raw.githubusercontent.com/Jaeik-Jeong/DeepComp/main/\"\n","\n","data_train_csv1 = pd.read_csv(address+\"data/\"+Renewable_Energy+'_16.csv', index_col=0)\n","data_train_csv2 = pd.read_csv(address+\"data/\"+Renewable_Energy+'_17.csv', index_col=0)\n","data_train_csv  = pd.concat([data_train_csv1, data_train_csv2])\n","data_val_csv    = pd.read_csv(address+\"data/\"+Renewable_Energy+'_18.csv', index_col=0)\n","data_test_csv   = pd.read_csv(address+\"data/\"+Renewable_Energy+'_19.csv', index_col=0)\n","\n","train_predict = np.array(pd.read_csv(address+\"results/\"+Renewable_Energy+\"_Model1_train.csv\", index_col=0))\n","val_predict = np.array(pd.read_csv(address+\"results/\"+Renewable_Energy+\"_Model1_val.csv\", index_col=0))\n","test_predict = np.array(pd.read_csv(address+\"results/\"+Renewable_Energy+\"_Model1_NEC.csv\", index_col=0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dxexWoP71odN"},"source":["# Data Preprocessing\n","\n","Battery_Size = 0.5\n","unit         = 4 #unit: 15 minute\n","\n","RE_Capacity1 = max(data_train_csv['Power(MW)'])\n","RE_Capacity2 = max(data_val_csv['Power(MW)'])\n","RE_Capacity3 = max(data_test_csv['Power(MW)'])\n","\n","size_train0 = int(len(data_train_csv)/unit)\n","size_val0   = int(len(data_val_csv)/unit)\n","size_test0  = int(len(data_test_csv)/unit)\n","\n","data_train0 = []\n","data_train  = []\n","for i in range(size_train0):\n","    data_train0 += [round(pd.Series.mean(data_train_csv['Power(MW)'][i*unit:(i+1)*unit])/RE_Capacity1, 3)]\n","    data_train  += [data_train0[i]] if data_train0[i] > 0 else []\n","\n","data_val0 = []\n","data_val  = []\n","for i in range(size_val0):\n","    data_val0 += [round(pd.Series.mean(data_val_csv['Power(MW)'][i*unit:(i+1)*unit])/RE_Capacity2, 3)]\n","    data_val  += [data_val0[i]] if data_val0[i] > 0 else []\n","\n","data_test0 = []\n","data_test  = []\n","for i in range(size_test0):\n","    data_test0 += [round(pd.Series.mean(data_test_csv['Power(MW)'][i*unit:(i+1)*unit])/RE_Capacity3, 3)]\n","    data_test  += [data_test0[i]] if data_test0[i] > 0 else []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IGQrvrAZZ4SG"},"source":["size_train = len(data_train)\n","size_val = len(data_val)\n","size_test = len(data_test)\n","\n","train_input = np.zeros((size_train-1, 1))\n","train_output = np.zeros((size_train-1, 1))\n","for i in range(size_train-1):\n","    train_input[i,:] = data_train[i]\n","    train_output[i,:] = data_train[i+1]\n","\n","val_input = np.zeros((size_val-1, 1))\n","val_output = np.zeros((size_val-1, 1))\n","for i in range(size_val-1):\n","    val_input[i,:] = data_val[i]\n","    val_output[i,:] = data_val[i+1]\n","\n","test_input = np.zeros((size_test-1, 1))\n","test_output = np.zeros((size_test-1, 1))\n","for i in range(size_test-1):\n","    test_input[i,:] = data_test[i]\n","    test_output[i,:] = data_test[i+1]\n","\n","print(\"MAPE_train: {}%\".format(round(100*np.mean(np.abs(train_predict - train_output)/train_output),2)).ljust(25), end=\"\")\n","print(\"MAPE_val: {}%\".format(round(100*np.mean(np.abs(val_predict - val_output)/val_output),2)).ljust(25), end=\"\")\n","print(\"MAPE_test: {}%\".format(round(100*np.mean(np.abs(test_predict - test_output)/test_output),2)).ljust(25))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1orT-K3n34nr"},"source":["# SARSA\n","\n","in_size       = 1\n","out_size      = 5\n","gamma         = 0.99\n","epsilon       = 0.9\n","batch_size    = 128\n","learning_rate = 0.001\n","\n","class SARSA(nn.Module):\n","    def __init__(self):\n","        super(SARSA, self).__init__()\n","        self.fc = nn.Linear(in_size, out_size)\n","\n","    def forward(self, x):\n","        x = self.fc(x)\n","        return x\n","        \n","def train_net(model, batch, optimizer):\n","    s_lst, a_lst, r_lst, s_prime_lst = [], [], [], []\n","\n","    for transition in batch:\n","        s, a, r, s_prime = transition\n","        s_lst.append(s)\n","        a_lst.append([a])\n","        r_lst.append([r])\n","        s_prime_lst.append(s_prime)\n","\n","    s,a,r,s_prime = torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n","                    torch.tensor(r_lst, dtype=torch.float), torch.tensor(s_prime_lst, dtype=torch.float)\n","            \n","    for i in range(10):\n","        q_out = model.forward(s).gather(1,a)\n","        target = r + gamma * torch.mean(model.forward(s_prime))\n","        loss = F.mse_loss(q_out, target)\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FM9xx8yDEf5x"},"source":["# Training SARSA\n","\n","E_max   = Battery_Size\n","tdelta  = unit/4\n","eff_c   = 0.9\n","eff_d   = 0.9\n","soc_min = 0.1\n","soc_max = 0.9\n","P_cmax  = Battery_Size/3\n","P_dmax  = Battery_Size/3\n","beta_c  = 0.01\n","beta_d  = 0.01\n","\n","E_cmax = eff_c*P_cmax*tdelta\n","E_dmax = (1/eff_d)*P_dmax*tdelta\n","C_max  = int(out_size/2)\n","\n","total_episode = 20\n","print_interval = 1\n","\n","model = SARSA()\n","act_train,  act_val,  act_test  = [], [], [] # Controlled Value\n","mape_train, mape_val, mape_test = [], [], [] # Mean Absolute Percentage Error\n","ccr_train,  ccr_val,  ccr_test  = [], [], [] # Complete Compensation Ratio\n","\n","batch = collections.deque(maxlen=batch_size+1)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","for n_epi in range(total_episode):\n","    act_train  += [[]]; act_val  += [[]]; act_test  += [[]]\n","    mape_train += [[]]; mape_val += [[]]; mape_test += [[]]\n","    ccr_train  += [[]]; ccr_val  += [[]]; ccr_test  += [[]]\n","\n","    state = [E_max/2]\n","    i = 0\n","    while i < size_train-1:\n","        for t in range(batch_size):\n","            coin = torch.rand(1).item()\n","            if coin < epsilon:\n","                action = np.random.choice(range(out_size))\n","            else:\n","                Qout = model.forward(torch.tensor(state, dtype=torch.float))\n","                action = np.argmax(Qout.tolist())\n","            E_c = min(max((E_cmax/C_max)*(action-C_max), 0.0), E_max*soc_max - state[0])\n","            E_d = min(max((E_dmax/C_max)*(C_max-action), 0.0), state[0] - E_max*soc_min)\n","\n","            real = train_output[i][0] + eff_d*E_d/tdelta - (1/eff_c)*E_c/tdelta\n","            pred = train_predict[i][0]\n","\n","            E = state[0] + E_c - E_d\n","            P_climit = min(P_cmax, (1/eff_c)*(E_max*soc_max - E)/tdelta)\n","            P_dlimit = min(P_dmax, eff_d*(E - E_max*soc_min)/tdelta)\n","            P_c = min(max(real-pred, 0), P_climit)\n","            P_d = min(max(pred-real, 0), P_dlimit)\n","            E_prime = E + eff_c*P_c*tdelta - (1/eff_d)*P_d*tdelta\n","            disp = 0.0 if np.isclose(real - P_c + P_d, 0) else real - P_c + P_d\n","            error = pred - disp\n","            error_function = abs(error) + beta_c*P_c + beta_d*P_d\n","\n","            next_state = [E_prime]\n","            reward = -error_function\n","            batch.append((state, action, reward, next_state))\n","            state = next_state[:]\n","\n","            act_train[n_epi]  += [E_c - E_d]\n","            mape_train[n_epi]  += [abs((pred-disp)/disp)] if disp != 0 else [0]\n","            ccr_train[n_epi] += [1 if np.isclose(pred-disp,0) else 0]\n","            i += 1\n","            if i == size_train-1:\n","                break\n","\n","        if n_epi != 0:\n","            train_net(model, batch, optimizer)\n","    \n","    state = [E_max/2]\n","    for k in range(size_val-1):\n","        Qout = model.forward(torch.tensor(state, dtype=torch.float))\n","        action = np.argmax(Qout.tolist())\n","        E_c = min(max((E_cmax/C_max)*(action-C_max), 0.0), E_max*soc_max - state[0])\n","        E_d = min(max((E_dmax/C_max)*(C_max-action), 0.0), state[0] - E_max*soc_min)\n","\n","        real = val_output[k][0] + eff_d*E_d/tdelta - (1/eff_c)*E_c/tdelta\n","        pred = val_predict[k][0]\n","\n","        E = state[0] + E_c - E_d\n","        P_climit = min(P_cmax, (1/eff_c)*(E_max*soc_max - E)/tdelta)\n","        P_dlimit = min(P_dmax, eff_d*(E - E_max*soc_min)/tdelta)\n","        P_c = min(max(real-pred, 0), P_climit)\n","        P_d = min(max(pred-real, 0), P_dlimit)\n","        E_prime = E + eff_c*P_c*tdelta - (1/eff_d)*P_d*tdelta\n","        disp = 0.0 if np.isclose(real - P_c + P_d, 0) else real - P_c + P_d\n","        error = pred - disp\n","        error_function = abs(error) + beta_c*P_c + beta_d*P_d\n","\n","        next_state = [E_prime]\n","        state = next_state[:]\n","\n","        act_val[n_epi]  += [E_c - E_d]\n","        mape_val[n_epi]  += [abs((pred-disp)/disp)] if disp != 0 else [0]\n","        ccr_val[n_epi] += [1 if np.isclose(pred-disp,0) else 0]\n","    \n","    state = [E_max/2]\n","    for l in range(size_test-1):\n","        Qout = model.forward(torch.tensor(state, dtype=torch.float))\n","        action = np.argmax(Qout.tolist())\n","        E_c = min(max((E_cmax/C_max)*(action-C_max), 0.0), E_max*soc_max - state[0])\n","        E_d = min(max((E_dmax/C_max)*(C_max-action), 0.0), state[0] - E_max*soc_min)\n","\n","        real = test_output[l][0] + eff_d*E_d/tdelta - (1/eff_c)*E_c/tdelta\n","        pred = test_predict[l][0]\n","\n","        E = state[0] + E_c - E_d\n","        P_climit = min(P_cmax, (1/eff_c)*(E_max*soc_max - E)/tdelta)\n","        P_dlimit = min(P_dmax, eff_d*(E - E_max*soc_min)/tdelta)\n","        P_c = min(max(real-pred, 0), P_climit)\n","        P_d = min(max(pred-real, 0), P_dlimit)\n","        E_prime = E + eff_c*P_c*tdelta - (1/eff_d)*P_d*tdelta\n","        disp = 0.0 if np.isclose(real - P_c + P_d, 0) else real - P_c + P_d\n","        error = pred - disp\n","        error_function = abs(error) + beta_c*P_c + beta_d*P_d\n","\n","        next_state = [E_prime]\n","        state = next_state[:]\n","\n","        act_test[n_epi]  += [E_c - E_d]\n","        mape_test[n_epi]  += [abs((pred-disp)/disp)] if disp != 0 else [0]\n","        ccr_test[n_epi] += [1 if np.isclose(pred-disp,0) else 0]\n","    \n","    if (n_epi+1)%print_interval == 0:\n","        MAPE_train = round(100*np.mean(mape_train[n_epi]),2)\n","        MAPE_val   = round(100*np.mean(mape_val[n_epi]),2)\n","        MAPE_test  = round(100*np.mean(mape_test[n_epi]),2)\n","        CCR_train  = round(np.mean(ccr_train[n_epi]),3)\n","        CCR_val    = round(np.mean(ccr_val[n_epi]),3)\n","        CCR_test   = round(np.mean(ccr_test[n_epi]),3)\n","\n","        print(\"episode: {}\".format(n_epi+1))\n","        print(\"MAPE_train: {}%\".format(MAPE_train).ljust(25), end=\"\")\n","        print(\"MAPE_val: {}%\".format(MAPE_val).ljust(25), end=\"\")\n","        print(\"MAPE_test: {}%\".format(MAPE_test).ljust(25))\n","        print(\"CCR_train: {}\".format(CCR_train).ljust(25), end=\"\")\n","        print(\"CCR_val: {}\".format(CCR_val).ljust(25), end=\"\")\n","        print(\"CCR_test: {}\".format(CCR_test).ljust(25))\n","        print(\"------------------------------------------------------------------------------------------\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LxA-zDA6Y02K"},"source":["# Produce results\n","#\n","#select_num = np.argmin(np.mean(mape_val,axis=1))\n","#select = pd.DataFrame(np.array(act_test[select_num][:]))\n","#select.to_csv(Renewable_Energy+\"_Model2_ECC+_\"+str(int(100*E_max))+\".csv\")"],"execution_count":null,"outputs":[]}]}